{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI for Earth System Science Hackathon 2020\n",
    "# HOLODEC Machine Learning Challenge Problem\n",
    "Matt Hayman, Aaron Bansemer, David John Gagne, Gabrielle Gantos, Gunther Wallach\n",
    "\n",
    "## Introduction\n",
    "![holodec probe on aircraft](holodec_images/image2.png)\n",
    "\n",
    "The properties of the water and ice particles in clouds are critical to many aspects of weather and climate.  The size, shape, and concentration of ice particles control the radiative properties of cirrus clouds.  The spatial distribution of water droplets in warm clouds may influence the formation of drizzle and rain.  The interactions among droplets, ice particles, and aerosols impact precipitation, lightning, atmospheric chemistry, and more.  Measurements of natural cloud particles are often taken aboard research aircraft with instruments mounted on the wings.  One of the newer technologies used for these instruments is inline holographic imaging, which has the important advantage of being able to instantaneously record all of the particles inside a small volume of air.  Using this technology, the Holographic Detector for Clouds (HOLODEC) has been developed by the university community and NCAR to improve our cloud measurement capabilities.\n",
    "\n",
    "A hologram captures electro-magnatic field amplitude and phase (or wavefront) incident on a detector.  In contrast, standard imaging captures only the amplitude of the electric field.  Unlike a standard image, holograms can be computationally refocused on any object within the capture volume using standard wave propagation calculations. The figure below shows an example of an inline hologram (large image) with five out of focus particles.  The five smaller images show the reconstruction from each particle by computationally propagating the electro-magnetic field back to the depth position of each particle. \n",
    "\n",
    "![holodec example images](holodec_images/image5.png)\n",
    "\n",
    "HOLODEC is an airborne holographic cloud imager capable of capturing particle size distributions in a single shot, so a measured particle size distribution is localized to a specific part of the cloud (not accumulated over a long path length).  By capturing a hologram, each particle can be imaged irrespective of its location in the sample volume, and its size and position can be accurately captured.\n",
    "\n",
    "While holographic imaging provides unparalleled information about cloud particles, processing the raw holograms is also computationally expensive.  Lacking prior knowledge of the particle position in depth, a typical HOLODEC hologram is reconstructed at 1000 planes (or depths) using standard diffraction calculations.  At each plane, a particle’s image sharpness is evaluated and the particle size and position is determined only at a plane where it is in focus.  In addition to the computational cost, the processing requires human intervention to recognize when a “particle” is really just artifacts of interfering scattered fields.\n",
    "\n",
    "The objective of this project is to develop a machine learning solution to process HOLODEC data that is more computationally efficient than the first-principles based processor.  \n",
    "\n",
    "An important factor in processing hologram data is that the scattered field from a particle spreads out as it propagates.  The image below shows the scattered field from a 50 µm particle at distances in increments of 0.1 mm from the particle (0 to 0.7 mm).  As the scattered field expands, it’s the power is also distributed over a larger area.\n",
    "\n",
    "![holodec 3d](holodec_images/image1.png)\n",
    "\n",
    "For simplicity, this project deals with simulated holographic data where particle shapes are limited to spheres.  Two datasets are provided.  The first dataset contains only one particle per hologram.  If you are successful in processing the first dataset, or you wish to immediately focus on a more challenging case, you can work on the second dataset that contains three particles per hologram.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Requirements\n",
    "This notebook requires Python >= 3.7. The following libraries are required:\n",
    "* numpy\n",
    "* scipy\n",
    "* matplotlib\n",
    "* xarray\n",
    "* pandas\n",
    "* scikit-learn\n",
    "* tensorflow >= 2.1\n",
    "* netcdf4\n",
    "* h5netcdf\n",
    "* tqdm\n",
    "* s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (1.18.2)\n",
      "Requirement already satisfied: scipy in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (1.3.2)\n",
      "Requirement already satisfied: matplotlib in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (3.2.1)\n",
      "Requirement already satisfied: xarray in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (0.15.1)\n",
      "Requirement already satisfied: pandas in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (1.0.3)\n",
      "Requirement already satisfied: scikit-learn in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (0.22.2.post1)\n",
      "Requirement already satisfied: tensorflow in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (2.2.0)\n",
      "Requirement already satisfied: netcdf4 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (1.5.3)\n",
      "Requirement already satisfied: h5netcdf in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (0.8.0)\n",
      "Requirement already satisfied: tqdm in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (4.45.0)\n",
      "Requirement already satisfied: s3fs in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: setuptools>=41.2 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from xarray) (46.1.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (1.29.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: cftime in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from netcdf4) (1.1.2)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from s3fs) (0.7.4)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from s3fs) (1.15.41)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (1.25.9)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.15.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /glade/work/ggantos/ncar_20200417/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scipy matplotlib xarray pandas scikit-learn tensorflow netcdf4 h5netcdf tqdm s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "The data summary should contain the following pieces of information:\n",
    "* Data generation procedure (satellite, model, etc.) \n",
    "* Link to website containing more information about dataset\n",
    "* Time span of the dataset\n",
    "* Geographic coverage of the dataset\n",
    "* Parameter space coverage (if synthetic)\n",
    "\n",
    "\n",
    "The datasets consist of synthetically-generated holograms of cloud droplets.  Each dataset is in netCDF format, and contains a series of hologram images as well as the properties of each particle in the image.  The netCDF variable names and properties are as follows:\n",
    "\n",
    "| Variable Name | Description | Dimensions | Units/Range|\n",
    "| ------------- | :----:|:----------- |:------|\n",
    "| image  | Stack of single-color images. Each image is 600x400 pixels, ranging from 0-255 in intensity. | nHolograms, 600, 400 | 0 to 255 (grayscale image) |\n",
    "| x  |  X-position of each particle in the dataset.  The origin is at the center of the hologram image. | nParticles (can vary) | -888 to 888 micrometers |\n",
    "| y  | Y-position of each particle in the dataset.  The origin is at the center of the hologram image. |  nParticles (can vary) | -592 to 592 micrometers |\n",
    "| z  | Z-position of each particle in the dataset.  The origin is at the focal plane of the instrument (all particles are unfocused). | nParticles (can vary) | 14000 to 158000 micrometers |\n",
    "| d  | Diameter of each simulated droplet | nParticles (can vary) | 20 to 70 micrometers |\n",
    "| hid | Hologram ID specifies which hologram this particle is contained in.  For example, if hid=1, the corresponding x, y, z, and d variables are found in the first hologram. | nParticles (can vary) | 1 to nHolograms |\n",
    "| Dx (global attribute) | Resolution of each pixel, == 2.96 micrometers.  Use if you wish to convert x/y position to pixel number |  |  |\n",
    "\n",
    "There are two datasets for this project, a single-particle dataset and a multi-particle dataset.  The single-particle dataset only contains one particle per hologram (nHolograms = nParticles). There are 50,000 holograms in the training dataset that correspond to 50,000 particles.\n",
    "\n",
    "The three-particle dataset contains three particles per hologram.  This dataset also contains 50,000 holograms but 150,000 particles.  Be sure to use the hid variable to figure out which hologram a particle is contained in.\n",
    "\n",
    "The goal of this project is to be able to find particles in the holograms and determine their x, y, z, and d values.\n",
    "\n",
    "<center><img src='holodec_images/image4.png'><center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Input Variables\n",
    "| Variable Name | Units | Description | Relevance |\n",
    "| ------------- | :----:|:----------- | :--------:|\n",
    "| hologram   |  arbitrary |  8 bit (0-255) amplitude captured by CCD  | standard input data for processing  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Variables\n",
    "| Variable Name | Units | Description |\n",
    "| ------------- | :----:|:----------- |\n",
    "| x  |  µm     |  particle horizontal position |\n",
    "| y  |  µm     |  particle vertical position  |\n",
    "| z  | µm  | particle position in depth (along the direction of propagation) |\n",
    "| d  | µm  | particle diameter |\n",
    "| hid | arbitrary | hologram ID by particle|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set\n",
    "\n",
    "The single-particle training dataset is in the netCDF format described above, with 50,000 holograms and 50,000 corresponding particles.\n",
    "\n",
    "The three-particle training dataset contains 50,000 holograms and 150,000 particles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set\n",
    "The single-particle validation dataset is in the netCDF format described above, with 10,000 holograms and 10,000 corresponding particles.\n",
    "\n",
    "The three-particle validation dataset contains 10,000 holograms and 30,000 particles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set\n",
    "The single-particle test dataset is in the netCDF format described above, with 10,000 holograms and 10,000 corresponding particles.\n",
    "\n",
    "The three-particle test dataset contains 10,000 holograms and 30,000 particles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import s3fs\n",
    "# import xarray as xr\n",
    "# fs = s3fs.S3FileSystem(anon=True)\n",
    "# bucket_files = fs.ls(\"ncar-aiml-data-commons/holodec\")\n",
    "# print(bucket_files)\n",
    "# fobj = fs.open(\"ncar-aiml-data-commons/holodec/synthetic_holograms_1particle_training.nc\")\n",
    "# ds = xr.open_dataset(fobj)\n",
    "# print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = ds[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# plt.pcolormesh(image[4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transforms\n",
    "\n",
    "The input images only need to be normalized between 0 and 1 by dividing by 255. The output *x*, *y*, *z*, and *d* should also be normalized using `sklearn.preprocessing` or a custom scalar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import sys\n",
    "import s3fs\n",
    "import yaml\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, MaxPool2D\n",
    "from tensorflow.keras.models import Model, save_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles_dict = {\n",
    "    1 : '1particle',\n",
    "    3 : '3particle',\n",
    "    'multi': 'multiparticle'}\n",
    "\n",
    "split_dict = {\n",
    "    'train' : 'training',\n",
    "    'test'   : 'test',\n",
    "    'valid': 'validation'}\n",
    "\n",
    "def dataset_name(num_particles, split):\n",
    "    \"\"\"Return the dataset filename given user inputs\"\"\"\n",
    "    \n",
    "    valid = [1,3,'multi']\n",
    "    if num_particles not in valid:\n",
    "        raise ValueError(\"results: num_particles must be one of %r.\" % valid)\n",
    "    num_particles = num_particles_dict[num_particles]\n",
    "    \n",
    "    valid = ['train','test','valid']\n",
    "    if split not in valid:\n",
    "        raise ValueError(\"results: split must be one of %r.\" % valid)\n",
    "    split = split_dict[split]\n",
    "    \n",
    "    return f'synthetic_holograms_{num_particles}_{split}.nc'\n",
    "\n",
    "def open_dataset(data_path, num_particles, split):\n",
    "    \"\"\"Return xarray dataset given user inputs\"\"\"\n",
    "    data_path = os.path.join(data_path, dataset_name(num_particles, split))\n",
    "    ds = xr.open_dataset(data_path)\n",
    "    return ds\n",
    "\n",
    "def scale_images(images):\n",
    "    \"\"\"Return images with pixel values between 0 and 1\"\"\"\n",
    "    return images.astype(np.float16)/255.\n",
    "\n",
    "def flatten_dataset(df):\n",
    "    columns = [\"x1\",\"y1\",\"z1\",\"d1\",\"x2\",\"y2\",\"z2\",\"d2\",\"x3\",\"y3\",\"z3\",\"d3\"]\n",
    "    data = []\n",
    "    for hid in df['hid'].unique():\n",
    "        vect = df.loc[df['hid'] == hid].drop(['hid'], axis=1).values\n",
    "        data.append(vect.flatten())\n",
    "    data = np.vstack(data)\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    return df\n",
    "\n",
    "def load_scaled_datasets(data_path, num_particles, output_cols, input_scaler):\n",
    "    \"\"\"Given the dataset particle numbers, returns scaled training and validation xarrays.\"\"\"\n",
    "    \n",
    "    beginning = datetime.now()\n",
    "    print(f\"BEGINNING: {beginning}\")\n",
    "    startTime = datetime.now()\n",
    "    print(\"Loading training and validation data\")\n",
    "    xr_train = open_dataset(data_path, num_particles, 'train')\n",
    "    xr_valid = open_dataset(data_path, num_particles, 'valid')\n",
    "    print(f\"\\t- time to load datasets: {datetime.now() - startTime}\")\n",
    "    \n",
    "    print(\"\\tScaling input data\")\n",
    "    start_time = datetime.now()\n",
    "    scaled_train_inputs = scale_images(xr_train[\"image\"])\n",
    "    print(f\"\\t\\tscaled_train_inputs.shape: {scaled_train_inputs.shape}\")\n",
    "    print(f\"\\t\\t- time to scale train input data: {datetime.now() - startTime}\")\n",
    "    start_time = datetime.now()\n",
    "    scaled_valid_inputs = scale_images(xr_valid[\"image\"])\n",
    "    print(f\"\\t\\tscaled_valid_inputs.shape: {scaled_valid_inputs.shape}\")\n",
    "    print(f\"\\t\\t- time to scale valid input data: {datetime.now() - startTime}\")\n",
    "    \n",
    "    print(\"\\tScaling output data\")\n",
    "    start_time = datetime.now()\n",
    "    train_outputs = xr_train[output_cols].to_dataframe()\n",
    "    valid_outputs = xr_valid[output_cols].to_dataframe()\n",
    "    print(f\"\\t\\t- time to slice output data: {datetime.now() - startTime}\")\n",
    "    \n",
    "    print(\"\\tScaling output data\")\n",
    "    if num_particles == 3:\n",
    "        train_outputs = flatten_dataset(train_outputs)\n",
    "        valid_outputs = flatten_dataset(valid_outputs)\n",
    "    \n",
    "    scaled_train_outputs = pd.DataFrame(input_scaler.fit_transform(train_outputs),\n",
    "                                        index=train_outputs.index, columns=train_outputs.columns)\n",
    "    print(f\"\\t\\tscaled_train_outputs.shape: {scaled_train_outputs.shape}\") \n",
    "    print(f\"\\t\\t- time to scale train output data: {datetime.now() - startTime}\")\n",
    "    scaled_valid_outputs = pd.DataFrame(input_scaler.transform(valid_outputs),\n",
    "                                        index=valid_outputs.index, columns=valid_outputs.columns)\n",
    "    print(f\"\\t\\tscaled_valid_outputs.shape: {scaled_valid_outputs.shape}\")\n",
    "    print(f\"\\t\\t- time to scale valid output data: {datetime.now() - startTime}\")\n",
    "    end = datetime.now()\n",
    "    print(f\"END: {end}\\nTIME ELAPSED: {end - beginning}\")\n",
    "\n",
    "    return scaled_train_inputs, scaled_valid_inputs, scaled_train_outputs, scaled_valid_outputs, input_scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Machine Learning Model\n",
    "A baseline model for solving this problem uses a ConvNET architecture implemented in Keras.  The first three convolution layers consist of 5 x 5 pixel kernels with rectified linear unit (relu) activation followed by a 4 x 4 pixel max pool layer.  The first convolution layer has 8 channels, the second contains 16 channels, and the third contains 32 channels.  The output of the third convolution layer is flattened and fed into a dense layer with 64 neurons and relu activation which then feeds into a second dense layer with 32 neurons and relu activation.  Finally the output layer consists of 4 neurons (for x, y, z and d outputs) and linear activation.  The model is trained using a mean absolute error (MAE) loss function.\n",
    "\n",
    "Mean absolute error in predictions for single-particle dataset:\n",
    "\n",
    "| Variable Name | Error |\n",
    "| ------------- |:----------- |\n",
    "| x  |  20 µm     |\n",
    "| y  |  12 µm     |\n",
    "| z  |  2519 µm     |\n",
    "| d  |  1 µm     |\n",
    "\n",
    "Training time: 20 epochs in 13 minutes\n",
    "\n",
    "Mean absolute error in predictions for three-particle dataset:\n",
    "\n",
    "| Variable Name | Error |\n",
    "| ------------- |:----------- |\n",
    "| x1  |  313 µm     |\n",
    "| y1  |  217 µm     |\n",
    "| z1  |  28872 µm     |\n",
    "| d1  |  10 µm     |\n",
    "| x2  |  326 µm     |\n",
    "| y2  |  213 µm     |\n",
    "| z2  |  28850 µm     |\n",
    "| d2  |  10 µm     |\n",
    "| x3  |  321 µm     |\n",
    "| y3  |  212 µm     |\n",
    "| z3  |  28580 µm     |\n",
    "| d3  |  10 µm     |\n",
    "\n",
    "Training time: 20 epochs in 13 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DNeuralNetwork(object):\n",
    "    \"\"\"\n",
    "    A Conv2D Neural Network Model that can support arbitrary numbers of layers.\n",
    "\n",
    "    Attributes:\n",
    "        filters: List of number of filters in each Conv2D layer\n",
    "        kernel_sizes: List of kernel sizes in each Conv2D layer\n",
    "        conv2d_activation: Type of activation function for conv2d layers\n",
    "        pool_sizes: List of Max Pool sizes\n",
    "        dense_sizes: Sizes of dense layers\n",
    "        dense_activation: Type of activation function for dense layers\n",
    "        learning_rate: Optimizer learning rate\n",
    "        optimizer: Name of optimizer or optimizer object.\n",
    "        loss: Name of loss function or loss object\n",
    "        batch_size: Number of examples per batch\n",
    "        epochs: Number of epochs to train\n",
    "        verbose: Level of detail to provide during training\n",
    "        model: Keras Model object\n",
    "    \"\"\"\n",
    "    def __init__(self, filters=(8,), kernel_sizes=(5,), conv2d_activation=\"relu\",\n",
    "                 pool_sizes=(4,), dense_sizes=(64,), dense_activation=\"relu\",\n",
    "                 lr=0.001, optimizer=\"adam\",  adam_beta_1=0.9, adam_beta_2=0.999,\n",
    "                 sgd_momentum=0.9, decay=0, loss=\"mae\", batch_size=32, epochs=2, verbose=0):\n",
    "        self.filters = filters\n",
    "        self.kernel_sizes = [tuple((v,v)) for v in kernel_sizes]\n",
    "        self.conv2d_activation = conv2d_activation\n",
    "        self.pool_sizes = [tuple((v,v)) for v in pool_sizes]\n",
    "        self.dense_sizes = dense_sizes\n",
    "        self.dense_activation = dense_activation\n",
    "        self.lr = lr\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer_obj = None\n",
    "        self.adam_beta_1 = adam_beta_1\n",
    "        self.adam_beta_2 = adam_beta_2\n",
    "        self.sgd_momentum = sgd_momentum\n",
    "        self.decay = decay\n",
    "        self.loss = loss\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "\n",
    "    def build_neural_network(self, input_shape, output_shape):\n",
    "        \"\"\"Create Keras neural network model and compile it.\"\"\"\n",
    "        conv_input = Input(shape=(input_shape), name=\"input\")\n",
    "        nn_model = conv_input\n",
    "        for h in range(len(self.filters)):\n",
    "            nn_model = Conv2D(self.filters[h], self.kernel_sizes[h], padding=\"same\",\n",
    "                              activation=self.conv2d_activation, name=f\"conv2D_{h:02d}\")(nn_model)\n",
    "            nn_model = MaxPool2D(self.pool_sizes[h], name=f\"maxpool2D_{h:02d}\")(nn_model)\n",
    "        nn_model = Flatten()(nn_model)\n",
    "        for h in range(len(self.dense_sizes)):\n",
    "            nn_model = Dense(self.dense_sizes[h], activation=self.dense_activation, name=f\"dense_{h:02d}\")(nn_model)\n",
    "        nn_model = Dense(output_shape, name=f\"dense_output\")(nn_model)\n",
    "        self.model = Model(conv_input, nn_model)\n",
    "        if self.optimizer == \"adam\":\n",
    "            self.optimizer_obj = Adam(lr=self.lr, beta_1=self.adam_beta_1, beta_2=self.adam_beta_2, decay=self.decay)\n",
    "        elif self.optimizer == \"sgd\":\n",
    "            self.optimizer_obj = SGD(lr=self.lr, momentum=self.sgd_momentum, decay=self.decay)\n",
    "        self.model.compile(optimizer=self.optimizer, loss=self.loss)\n",
    "        self.model.summary()\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        if len(x.shape[1:])==2:\n",
    "            x = np.expand_dims(x, axis=-1)\n",
    "        if len(y.shape) == 1:\n",
    "            output_shape = 1\n",
    "        else:\n",
    "            output_shape = y.shape[1]\n",
    "        input_shape = x.shape[1:]\n",
    "        self.build_neural_network(input_shape, output_shape)\n",
    "        self.model.fit(x, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose)\n",
    "        return\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_out = self.model.predict(np.expand_dims(x.values, axis=-1), batch_size=self.batch_size)\n",
    "        return y_out\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        y_prob = self.model.predict(x, batch_size=self.batch_size)\n",
    "        return y_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can explore with whichever sklearn.processing or custom scalar\n",
    "# you can also define a different sklearn or custom error functions\n",
    "scalers = {\"MinMaxScaler\": MinMaxScaler,\n",
    "           \"MaxAbsScaler\": MaxAbsScaler,\n",
    "           \"StandardScaler\": StandardScaler,\n",
    "           \"RobustScaler\": RobustScaler}\n",
    "metrics = {\"mae\": mean_absolute_error}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml file equivalent variable definitions\n",
    "\n",
    "data_path = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/\"\n",
    "out_path = \"/glade/p/cisl/aiml/ggantos/holodec/conv2d_1particle_test_nb/\"\n",
    "model_name = \"cnn\"\n",
    "num_particles = 1\n",
    "random_seed = 328942\n",
    "output_cols = [\"x\", \"y\", \"z\", \"d\"]\n",
    "input_scaler = scalers[\"MinMaxScaler\"]()\n",
    "metric = metrics[\"mae\"]\n",
    "\n",
    "# conv2d_network definitions\n",
    "filters = [8, 16, 32]\n",
    "kernel_sizes = [5, 5, 5]\n",
    "conv2d_activation = \"relu\"\n",
    "pool_sizes = [4, 4, 4]\n",
    "dense_sizes = [64, 32]\n",
    "dense_activation = \"relu\"\n",
    "lr = 0.001\n",
    "optimizer = \"adam\"\n",
    "loss = \"mae\"\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "verbose = 1\n",
    "\n",
    "if not exists(out_path):\n",
    "    os.makedirs(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING: 2020-06-18 16:53:21.025504\n",
      "Loading training and validation data\n",
      "\t- time to load datasets: 0:00:00.185260\n",
      "\tScaling input data\n",
      "\t\tscaled_train_inputs.shape: (50000, 600, 400)\n",
      "\t\t- time to scale train input data: 0:07:24.263104\n",
      "\t\tscaled_valid_inputs.shape: (10000, 600, 400)\n",
      "\t\t- time to scale valid input data: 0:08:46.373059\n",
      "\tScaling output data\n",
      "\t\t- time to slice output data: 0:08:46.480836\n",
      "\tScaling output data\n",
      "\t\tscaled_train_outputs.shape: (50000, 4)\n",
      "\t\t- time to scale train output data: 0:08:46.484024\n",
      "\t\tscaled_valid_outputs.shape: (10000, 4)\n",
      "\t\t- time to scale valid output data: 0:08:46.484890\n",
      "END: 2020-06-18 17:02:07.510498\n",
      "TIME ELAPSED: 0:08:46.484994\n"
     ]
    }
   ],
   "source": [
    "# load and normalize data (this takes approximately 8-10 minutes)\n",
    "scaled_train_inputs, \\\n",
    "scaled_valid_inputs, \\\n",
    "scaled_train_outputs, \\\n",
    "scaled_valid_outputs, \\\n",
    "input_scaler = load_scaled_datasets(data_path,\n",
    "                                    num_particles,\n",
    "                                    output_cols,\n",
    "                                    input_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Conv2DNeuralNetwork(filters=filters, kernel_sizes=kernel_sizes, conv2d_activation=conv2d_activation,\n",
    "                 pool_sizes=pool_sizes, dense_sizes=dense_sizes, dense_activation=dense_activation,\n",
    "                 lr=lr, optimizer=optimizer, loss=loss, batch_size=batch_size, epochs=epochs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 600, 400, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2D_00 (Conv2D)           (None, 600, 400, 8)       208       \n",
      "_________________________________________________________________\n",
      "maxpool2D_00 (MaxPooling2D)  (None, 150, 100, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2D_01 (Conv2D)           (None, 150, 100, 16)      3216      \n",
      "_________________________________________________________________\n",
      "maxpool2D_01 (MaxPooling2D)  (None, 37, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2D_02 (Conv2D)           (None, 37, 25, 32)        12832     \n",
      "_________________________________________________________________\n",
      "maxpool2D_02 (MaxPooling2D)  (None, 9, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_00 (Dense)             (None, 64)                110656    \n",
      "_________________________________________________________________\n",
      "dense_01 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 129,124\n",
      "Trainable params: 129,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 0.1420\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 0.0584\n",
      "Running model took 0:02:45.448197 time\n"
     ]
    }
   ],
   "source": [
    "# build and train the model\n",
    "model_start = datetime.now()\n",
    "mod = Conv2DNeuralNetwork(filters=filters, kernel_sizes=kernel_sizes, conv2d_activation=conv2d_activation,\n",
    "                 pool_sizes=pool_sizes, dense_sizes=dense_sizes, dense_activation=dense_activation,\n",
    "                 lr=lr, optimizer=optimizer, loss=loss, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "mod.fit(scaled_train_inputs.values, scaled_train_outputs.values)\n",
    "print(f\"Running model took {datetime.now() - model_start} time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "print(\"Saving the model\")\n",
    "mod.model.save(join(out_path, model_name +\".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict outputs\n",
    "scaled_pred_valid_outputs = pd.DataFrame(mod.predict(scaled_valid_inputs),\n",
    "                                         index=scaled_valid_outputs.index,\n",
    "                                         columns=scaled_valid_outputs.columns)\n",
    "scaled_pred_train_outputs = pd.DataFrame(mod.predict(scaled_train_inputs),\n",
    "                                         index=scaled_train_outputs.index,\n",
    "                                         columns=scaled_train_outputs.columns)\n",
    "\n",
    "# apply inverse scaler to outputs\n",
    "pred_train_outputs = input_scaler.inverse_transform(scaled_pred_train_outputs)        \n",
    "pred_valid_outputs = input_scaler.inverse_transform(scaled_pred_valid_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "pd.DataFrame(data=pred_valid_outputs).to_csv(join(out_path, \"pred_valid_outputs.csv\"), index=False)\n",
    "pd.DataFrame(data=pred_train_outputs).to_csv(join(out_path, \"pred_train_outputs.csv\"), index=False)\n",
    "pd.DataFrame(data=scaled_pred_train_outputs).to_csv(join(out_path, \"scaled_pred_train_outputs.csv\"), index=False)\n",
    "pd.DataFrame(data=scaled_pred_valid_outputs).to_csv(join(out_path, \"scaled_pred_valid_outputs.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "An ideal solution to HOLODEC processing would leverage all the advantages of the instrument (unparalleled particle position and size accuracy) but reduce the drawbacks (processing time).  For this reason, the major components of the model assessment should include:\n",
    "* MAE, and maximum error of each output (x, y, z, d)\n",
    "* Processing time per hologram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error in x:  43.12374\n",
      "Training error in y:  56.21668\n",
      "Training error in z:  8639.359\n",
      "Training error in d:  2.571705\n",
      "Validation error in x:  43.80616\n",
      "Validation error in y:  57.166668\n",
      "Validation error in z:  8780.571\n",
      "Validation error in d:  2.6228693\n"
     ]
    }
   ],
   "source": [
    "# calculate error\n",
    "train_outputs = open_dataset(data_path, num_particles, \"train\")[output_cols].to_dataframe()\n",
    "valid_outputs = open_dataset(data_path, num_particles, \"valid\")[output_cols].to_dataframe()\n",
    "if len(output_cols) == 5:\n",
    "    train_outputs = flatten_dataset(train_outputs)\n",
    "    valid_outputs = flatten_dataset(valid_outputs)\n",
    "error = {\"train\": {}, \"valid\": {}}\n",
    "for i, var in enumerate(train_outputs.columns):\n",
    "    err = mean_absolute_error(train_outputs[var], pred_train_outputs[:,i])\n",
    "    error[\"train\"][var] = err\n",
    "    print (f\"Training error in {var}: \", err)\n",
    "for i, var in enumerate(valid_outputs.columns):\n",
    "    err = mean_absolute_error(valid_outputs[var], pred_valid_outputs[:,i])\n",
    "    error[\"valid\"][var] = err\n",
    "    print (f\"Validation error in {var}: \", err)    \n",
    "\n",
    "pd.DataFrame.from_dict(error, orient='index').to_csv(join(out_path, \"error.csv\"),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
